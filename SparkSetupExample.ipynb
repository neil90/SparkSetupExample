{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is just a template that I regularly use for Jupyter and Spark 2.10\n",
    "\n",
    "#If Spark isn't added to PYTHONPATH then do it here, this is with EMR\n",
    "#spark_home = '/usr/lib/spark'\n",
    "#sys.path.insert(0, spark_home + \"/python\")\n",
    "#sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.4-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\\\n",
    "    .setMaster(\"yarn-client\")\\\n",
    "    .setAppName(\"SparkSetupExample\")\\\n",
    "    .set('spark.executor.memory', '4g')\\\n",
    "    .set('spark.executor.cores', '2')\\\n",
    "    .set('spark.executor.instances','2')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config(conf=sc.getConf())\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
